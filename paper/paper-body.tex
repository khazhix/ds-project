\section{Introduction}

A palindrome is a string that reads the same both ways.
Palindromic patterns appear in many research areas, from
formal language theory to molecular biology.

There are a lot of papers introducing algorithms and data structures
to facilitate different problems that involve palindromes.
One such data structure is EERTREE, a recently described
linear-sized palindromic tree introduced by Rubinchik \cite{RUBINCHIK2018249}.

In this project we aim to design at least one purely functional and
fully persistent version of a palindromic tree, implement it
in Haskell programming language and compare it
with other existing solutions. We are going to start with
a naive implementation and gradually arrive at an efficient
version, relying on some of the techniques described by
Okasaki \cite{Okasaki1998} for designing purely functional data structures.

We hope that purely functional variations will prove valuable
for some divide-and-conquer approaches to palindromic analysis.
We also believe that a fully persistent version might be useful
for comparative analysis of closely-related strings
(such as RNA string mutations).

Compared to earlier work, our new contributions are these:

\begin{itemize}
\item We introduce an efficient purely functional version of palindromic tree,
  and provide an implementation in Haskell, a non-strict, purely-functional
  programming language; we also prove that although adding symbols is $\mathcal{O}(\log{}n)$ worst case, it is $\Theta(1)$ on average.
\item We provide a variation of that data structure that is more
  friendly to garbage collection, and demonstrate its efficiency
  by counting rich strings of length from $1$ to $n$ in $\mathcal{O}(n)$ memory;
\item We design a double-ended variation with new $prepend$
  and $merge$ operations, and show that $merge$ can be implemented
  with $\mathcal{O}(1)$ time and space on average;
\end{itemize}

\section{Finding palindromes}

Many of the problems that involve palindromes rely essentially on finding
all palindromes in a given sequence, possibly keeping track of some extra information
(such as number and indices of occurrences).

To the best of our knowledge state of the art for this are Manacher's algorithm
and Rubinchik's EERTREE. Both allow processing string in $\mathcal{O}(n)$ and

\emph{Here we should describe the problem that we are trying to solve.}

Let $Pal(S)$ be the set of all occurrences of all
palindromes in a string $S$:
$$
Pal(S) = \{ \langle p, i \rangle | S_{i..j} = p, isPalindrome(p) \}
$$

Note that by storing a palindrome occurrence together with its index
makes it unique (for a given string) and allows us to perform further
analysis. For instance, we can compute total number of occurrences
for each palindrome and find a refren-palindrome.

\ldots

\section{Palindromic tree}

\subsection{Na√Øve palindromic tree}

\subsection{Infinite palindromic tree}

\subsection{First applications}

\section{Memory efficiency}

\subsection{Counting rich strings}

\section{Double-ended palindromic tree}

\subsection{Appending symbols}

\emph{Here we mention that prefixes and suffixes
in palindromes are the same, so we adjust data structure
to keep track of both without much changes and no
additional asymptotic complexity.}

\subsection{Merging}

As has been shown by Rubinchik and Manacher, it is possible
to process a string in linear time. Above we have shown that
a similar result can be achieved in a purely functional setting.
But all mentioned approaches are inherently sequential and
do not allow for an obvious parallelisation to speed up processing
large strings.

Our idea and, perhaps, main contribution of this paper is
design of a merge operation that allows
us to process two strings separately and combine results
efficiently.

$$
merge(S_1, S_2) = Pals(S_1 + S_2)
$$

The idea behind implementation of merge is very simple:
we append (or prepend) symbols from one string to another
until we know we will not encounter any new palindromes.

To arrive at this implementation and prove its correctness
we need first to formalise a few observations.

We define $NewPals(S_1, S_2)$ to be the set of
new palindrome occurences, formed after catenation of $S_1$ and $S_2$:
$$
NewPals(S_1, S_2) = Pals(S_1 + S_2) - Pals(S_1) - Pals(S_2)
$$

First observation is trivial,
but lets us focus only on the important part of the strings.

\begin{lemma}
\label{lemma-newpals-cover}
  For any two strings $S_1$ and $S_2$
  every new palindrome occurence
  $\langle p, i \rangle \in NewPals(S_1, S_2)$
  will always cover the catenation point:
  $$
  i < \|S_1\| \le \land i + \|p\|
  $$
\end{lemma}
\begin{proof}
  \emph{To be done by Timur Khazhiev.}
\end{proof}

Lemma \ref{lemma-newpals-cover} hints that we can implement
merge by prepending (or appending) symbols, but stop prematurely!
The next lemma helps us figure out when exactly we can stop.

\begin{lemma}
\label{lemma-merge-new-center-interval}
  For any two strings $S_1$ and $S_2$
  every new palindrome occurence
  $\langle p, i \rangle \in NewPals(S_1, S_2)$
  will have its center
  between centers of maximum palindrome suffix of $S_1$
  and maximum palindrome prefix of $S_2$:
  $$
  \|S_1\| - \frac{\|\mathit{maxSuff}(S_1)\|}{2} \le
  i + \frac{\|p\|}{2} \le
  \|S_1\| + \frac{\|\mathit{maxPref}(S_2)\|}{2}
  $$
\end{lemma}
\begin{proof}
  \emph{To be done by Timur Khazhiev.}
\end{proof}

Can we stop after new maximum palindome suffix (prefix)
has its center outside the interval mentioned in Lemma \ref{lemma-merge-new-center-interval}?
This final lemma helps answer that question:

\begin{lemma}
\label{lemma-center-move}
  Let $S'$ be the result of appending (prepending) symbol $c$ to string $S$.
  Then its maximum palindrome suffix center either stays in place
  or moves to the right (to the left):
  $$
  \|S\| - \frac{\|\mathit{maxSuff}(S)\|}{2} \le \|S'\| - \frac{\|\mathit{maxSuff}(S')\|}{2}
  $$
\end{lemma}
\begin{proof}
  \emph{To be done by Timur Khazhiev.}
\end{proof}

Now all ingredients are in place to implement $merge$
that runs linearly in \textit{(number of suffixes/prefixes we need to update?)}.

\begin{theorem}
  There is an algorithm that implements $merge$ in $\Theta(K)$,
  where $K$ is the maximum index in $S_2$ (correspondingly $S_1$)
  corresponding to the rightmost (leftmost)
  of new palindrome occurrences $NewPals(S_1, S_2)$.
  \emph{This formulation should be rewritten more clearly.}
\end{theorem}
\begin{proof}
  \emph{To be done by Timur Khazhiev.}
\end{proof}

\begin{corollary}
  There is an algorithm that implements $merge(S_1, S_2)$
  in $\mathcal{O}(min(\|S_1\|, \|S_2\|))$ worst-case.
\end{corollary}
\begin{proof}
  \emph{To be done by Timur Khazhiev.}
\end{proof}

As we can see, $merge$ can be implemented as simple update
to the continuous appending (prepending) with virtually no overhead.
In fact, since our implementation allows for early exit,
it performs better than mere appending for many strings.
For example, \ldots

Interestingly, $merge$ will exit early most of the time.
More precisely, it will exit in constant time on average.

\begin{theorem}
  $merge$ is $\mathcal{O}(1)$ on average.
\end{theorem}
\begin{proof}
  \emph{To be done by Timur Khazhiev. Hint: use theorem about average length of a maximum palindrome suffix.}
\end{proof}

\section{Complexity Analysis}

Working with maximum palindromic suffixes and prefixes
is central to most operations with palindromic trees.
So to understand complexities of these operations we
study length of such suffixes and prefixes first.

\begin{lemma}
\label{lemma-palindrome-prob}
  A random string of length $n$ is a palindrome with probability $\sigma^{- \lfloor\frac{n}{2}\rfloor}$.
\end{lemma}
\begin{proof}
  For a random string to be a palindrome its first $\lfloor\frac{n}{2}\rfloor$
  symbols must match symbols from the right half exactly, leaving only
  $1$ valid candidate out of $\sigma^{\lfloor\frac{n}{2}\rfloor}$.
\end{proof}

\begin{theorem}
  Average length of the maximum palindromic suffix
  of a random string of length $n$ is $\Theta(1)$
  for alphabets of size $\sigma \ge 2$.
\end{theorem}
\begin{proof}
  Let $L_{avg}(n)$ be the average length of the maximum palindromic suffix
  of a random string of length $n$.
  $L_{avg}(n) \ge 0$, so to prove $L_{avg}(n)$ is $\Theta(1)$ we need
  to find a constant upper bound.

  Let $P_{max}(k, n)$ be the probability that a string of length $n$
  has maximum palindromic suffix of length $k$.
  Then $L_{avg}(n)$ can be expressed as a weighted sum:
  $$
  L_{avg}(n) = \sum_{k=1}^{n} k \cdot P_{max}(k, n)
  $$
  We notice that for a string to have a maximum palindromic suffix
  of length $k$ it is necessary that last $k$ symbols form a palindrome.
  Using Lemma~\ref{lemma-palindrome-prob} together with that observation
  we get an upper bound of $P_{max}(k, n)$:
  $$
  P_{max}(k, n) \le \sigma^{- \lfloor\frac{k}{2}\rfloor}
  $$
  This allows us to derive an upper bound for $L_{avg}(n)$:
  \begin{align*}
    L_{avg}(n)
      &\le \sum_{k=1}^{n} k \cdot \sigma^{- \lfloor\frac{k}{2}\rfloor}
       \le \sum_{k=1}^{n} k \cdot \sigma^{- \frac{k-1}{2}}
       \le \sum_{k=1}^{\infty} k \cdot \sigma^{- \frac{k-1}{2}} \\
      &= \frac{\sigma}{(\sqrt{\sigma} - 1)^2}
       = \mathcal{O}(1)
  \end{align*}
\end{proof}

\begin{corollary}
  $L_{avg}(n) < 12$ for $\sigma = 2$.
\end{corollary}

\begin{corollary}
  $L_{avg}(n) \le 4$ for $\sigma = 4$.
\end{corollary}

\begin{theorem}
  Adding a symbol to the end of the eertree of
  a string of length $n$ is $\Theta(1)$ on average,
  but $\mathcal{O}(\log{}n)$ worst case.
\end{theorem}
\begin{proof}
  \emph{To be done by Timur Khazhiev.}
\end{proof}

\section{Related and future work}

\section{Conclusion}

